{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will combine train and test set, creating a column 'is_train'\n",
    "# for later when we separate them back\n",
    "def concat_df(train, test):\n",
    "    test['is_train'] = False\n",
    "    train['is_train'] = True\n",
    "    combined = pd.concat([train, test], sort=False)\n",
    "    return combined\n",
    "\n",
    "# function that will separate the combined df\n",
    "def separate_df(combined):\n",
    "    train = combined[combined['is_train'] == True].drop('is_train', axis=1)\n",
    "    test = combined[combined['is_train'] == False].drop('is_train', axis=1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine test and train data to preprocess the data all together.\n",
    "df_combined = concat_df(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      " 14  is_train      12970 non-null  bool   \n",
      "dtypes: bool(1), float64(6), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person is in cryosleep, they would not be able to spend any money so\n",
    "# we can fill null with 0 for money spent columns and false for VIP column\n",
    "money_col = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "vip = ['VIP']\n",
    "condition = (df_combined['CryoSleep'] == True)\n",
    "\n",
    "df_combined.loc[condition, money_col] = df_combined.loc[condition, money_col].fillna(0)\n",
    "df_combined.loc[condition, vip] = df_combined.loc[condition, vip].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person have not spent any money, it is likely that person is in cryosleep.\n",
    "cryo = ['CryoSleep']\n",
    "\n",
    "# the condition is True if all the money_col values are 0\n",
    "condition = (df_combined[money_col].eq(0).all(axis=1))\n",
    "\n",
    "df_combined.loc[condition, cryo] = df_combined.loc[condition, cryo].fillna(True)\n",
    "df_combined['CryoSleep'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mode of HomePlanet, Destination and impute it for null\n",
    "\n",
    "mode_homeplanet = df_combined['HomePlanet'].mode()[0]\n",
    "mode_destination = df_combined['Destination'].mode()[0]\n",
    "\n",
    "df_combined['HomePlanet'].fillna(mode_homeplanet, inplace=True)\n",
    "df_combined['Destination'].fillna(mode_destination, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change boolean variable cryosleep to integer values\n",
    "df_combined['CryoSleep'] = df_combined['CryoSleep'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         0\n",
       "CryoSleep          0\n",
       "Cabin            299\n",
       "Destination        0\n",
       "Age              270\n",
       "VIP              192\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "Name             294\n",
       "Transported     4277\n",
       "is_train           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute 1st IQR to replace null values in money_col\n",
    "\n",
    "cryo_sleep_1 = df_combined[df_combined['CryoSleep'] == 1]\n",
    "first_quartiles = cryo_sleep_1[money_col].quantile(0.25)\n",
    "print(first_quartiles['FoodCourt'])\n",
    "for col in money_col:\n",
    "    df_combined[col].fillna(first_quartiles[col], inplace=True)\n",
    "\n",
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_means = df_combined.groupby(['HomePlanet', 'CryoSleep', 'Destination'])['Age'].mean()\n",
    "# print(group_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cabin and Age, input 'Z/0/N' and 'Unknown' just to use the data without deleting the row\n",
    "\n",
    "df_combined['Cabin'] = df_combined['Cabin'].fillna('Z/0/N')\n",
    "df_combined['Name'] = df_combined['Name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since 'Cabin' column has three components, we can slit them into three columns\n",
    "\n",
    "cabin_split = df_combined['Cabin'].str.split('/', expand=True)\n",
    "cabin_split.columns = ['Deck', 'RoomNumber', 'Side']\n",
    "ndf = pd.concat([df_combined, cabin_split], axis=1)\n",
    "df_combined = ndf\n",
    "df_combined.drop(columns=['Cabin'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NA values for Age column\n",
    "\n",
    "group_means = df_combined.groupby(['CryoSleep', 'HomePlanet', 'Destination'], group_keys=True)['Age'].mean().reset_index(name='Age_mean')\n",
    "df_combined = df_combined.merge(group_means, on=['CryoSleep', 'HomePlanet', 'Destination'], how='left')\n",
    "df_combined['Age'] = df_combined['Age'].fillna(df_combined['Age_mean'])\n",
    "df_combined.drop(columns=['Age_mean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_mean_hpna = df_combined.groupby(['CryoSleep', 'Destination'], group_keys=True)['Age'].mean().reset_index(name='Age_mean_hpna')\n",
    "# group_mean_dtna = df_combined.groupby(['CryoSleep', 'HomePlanet'], group_keys=True)['Age'].mean().reset_index(name='Age_mean_dtna')\n",
    "\n",
    "# df_combined = df_combined.merge(group_mean_hpna, on=['CryoSleep', 'Destination'], how='left')\n",
    "# df_combined = df_combined.merge(group_mean_dtna, on=['CryoSleep', 'HomePlanet'], how='left')\n",
    "\n",
    "# df_combined['Age'] = df_combined.apply(\n",
    "#     lambda row: row['Age_mean_hpna'] if pd.isnull(row['HomePlanet']) and not pd.isnull(row['Age_mean_hpna']) \n",
    "#     else row['Age_mean_dtna'] if pd.isnull(row['Destination']) and not pd.isnull(row['Age_mean_dtna']) \n",
    "#     else row['Age'],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df_combined.drop(columns=['Age_mean_hpna', 'Age_mean_dtna'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle null values in VIP column, first made a new column 'TotalSpent' adding up all the money spent\n",
    "\n",
    "df_combined['TotalSpent'] = df_combined[money_col].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      273.000000\n",
       "mean      4595.542125\n",
       "std       5464.818112\n",
       "min          0.000000\n",
       "25%       1299.000000\n",
       "50%       2743.000000\n",
       "75%       6206.000000\n",
       "max      33666.000000\n",
       "Name: TotalSpent, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the minimum value of total spent when vip = 1\n",
    "\n",
    "vip = df_combined[df_combined['VIP'] == 1]\n",
    "#vip = df_combined[df_combined['VIP'] == 0]\n",
    "min_vip = vip['TotalSpent']\n",
    "min_vip.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for null vip, let's assume if a person spent over 2743 dollars, they are vips\n",
    "\n",
    "df_combined.loc[df_combined['VIP'].isnull(), 'VIP'] = df_combined['TotalSpent'] >= 2743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         0\n",
       "CryoSleep          0\n",
       "Destination        0\n",
       "Age                0\n",
       "VIP                0\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "Name               0\n",
       "Transported     4277\n",
       "is_train           0\n",
       "Deck               0\n",
       "RoomNumber         0\n",
       "Side               0\n",
       "TotalSpent         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>129</td>\n",
       "      <td>207</td>\n",
       "      <td>239</td>\n",
       "      <td>271</td>\n",
       "      <td>563</td>\n",
       "      <td>1565</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>127</td>\n",
       "      <td>572</td>\n",
       "      <td>508</td>\n",
       "      <td>207</td>\n",
       "      <td>313</td>\n",
       "      <td>1229</td>\n",
       "      <td>1321</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck           A    B    C    D    E     F     G  T    Z\n",
       "Transported                                             \n",
       "False        129  207  239  271  563  1565  1238  4   99\n",
       "True         127  572  508  207  313  1229  1321  1  100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_combined, index='Transported', columns='Deck', values='PassengerId', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data for money_col is very skewed, take log and then standardize\n",
    "# taking log\n",
    "\n",
    "for column in money_col:\n",
    "   df_combined[column + '_log'] = np.log1p(df_combined[column])\n",
    "   df_combined.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding for categorical variables that will be used, and change bool to int\n",
    "\n",
    "df_combined = pd.get_dummies(df_combined, columns=['HomePlanet', 'Deck', 'Side', 'Destination'])\n",
    "df_combined['VIP'] = df_combined['VIP'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Data columns (total 32 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PassengerId                12970 non-null  object \n",
      " 1   CryoSleep                  12970 non-null  int32  \n",
      " 2   Age                        12970 non-null  float64\n",
      " 3   VIP                        12970 non-null  int32  \n",
      " 4   Name                       12970 non-null  object \n",
      " 5   Transported                8693 non-null   object \n",
      " 6   is_train                   12970 non-null  bool   \n",
      " 7   RoomNumber                 12970 non-null  object \n",
      " 8   TotalSpent                 12970 non-null  float64\n",
      " 9   RoomService_log            12970 non-null  float64\n",
      " 10  FoodCourt_log              12970 non-null  float64\n",
      " 11  ShoppingMall_log           12970 non-null  float64\n",
      " 12  Spa_log                    12970 non-null  float64\n",
      " 13  VRDeck_log                 12970 non-null  float64\n",
      " 14  HomePlanet_Earth           12970 non-null  bool   \n",
      " 15  HomePlanet_Europa          12970 non-null  bool   \n",
      " 16  HomePlanet_Mars            12970 non-null  bool   \n",
      " 17  Deck_A                     12970 non-null  bool   \n",
      " 18  Deck_B                     12970 non-null  bool   \n",
      " 19  Deck_C                     12970 non-null  bool   \n",
      " 20  Deck_D                     12970 non-null  bool   \n",
      " 21  Deck_E                     12970 non-null  bool   \n",
      " 22  Deck_F                     12970 non-null  bool   \n",
      " 23  Deck_G                     12970 non-null  bool   \n",
      " 24  Deck_T                     12970 non-null  bool   \n",
      " 25  Deck_Z                     12970 non-null  bool   \n",
      " 26  Side_N                     12970 non-null  bool   \n",
      " 27  Side_P                     12970 non-null  bool   \n",
      " 28  Side_S                     12970 non-null  bool   \n",
      " 29  Destination_55 Cancri e    12970 non-null  bool   \n",
      " 30  Destination_PSO J318.5-22  12970 non-null  bool   \n",
      " 31  Destination_TRAPPIST-1e    12970 non-null  bool   \n",
      "dtypes: bool(19), float64(7), int32(2), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "#money_col_log = ['RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log']\n",
    "#scaled_columns = scaler.fit_transform(df_combined[money_col_log])\n",
    "#for i, col in enumerate(money_col_log):\n",
    "#    df_combined[col + '_scaled'] = scaled_columns[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the combined df to train and test\n",
    "\n",
    "df_combined = df_combined.drop(['Name', 'PassengerId', 'RoomNumber'], axis=1)\n",
    "df_train, df_test = separate_df(df_combined)\n",
    "df_train['Transported'] = df_train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Transported', axis=1)\n",
    "y = df_train['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918343875790684"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pipeline\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('svm', SVC())])\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7987349051178838"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_k5 = Pipeline([('Feature_Selection', SelectKBest(f_classif, k=16)),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('svm', SVC())])\n",
    "pipe_k5.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918343875790684"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier())])\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
