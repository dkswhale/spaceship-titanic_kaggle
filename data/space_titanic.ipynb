{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will combine train and test set, creating a column 'is_train'\n",
    "# for later when we separate them back\n",
    "def concat_df(train, test):\n",
    "    test['is_train'] = False\n",
    "    train['is_train'] = True\n",
    "    combined = pd.concat([train, test], sort=False)\n",
    "    return combined\n",
    "\n",
    "# function that will separate the combined df\n",
    "def separate_df(combined):\n",
    "    train = combined[combined['is_train'] == True].drop('is_train', axis=1)\n",
    "    test = combined[combined['is_train'] == False].drop('is_train', axis=1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine test and train data to preprocess the data all together.\n",
    "df_combined = concat_df(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      " 14  is_train      12970 non-null  bool   \n",
      "dtypes: bool(1), float64(6), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person is in cryosleep, they would not be able to spend any money so\n",
    "# we can fill null with 0 for money spent columns and false for VIP column\n",
    "money_col = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "vip = ['VIP']\n",
    "condition = (df_combined['CryoSleep'] == True)\n",
    "\n",
    "df_combined.loc[condition, money_col] = df_combined.loc[condition, money_col].fillna(0)\n",
    "df_combined.loc[condition, vip] = df_combined.loc[condition, vip].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person have not spent any money, it is likely that person is in cryosleep.\n",
    "cryo = ['CryoSleep']\n",
    "\n",
    "# the condition is True if all the money_col values are 0\n",
    "condition = (df_combined[money_col].eq(0).all(axis=1))\n",
    "\n",
    "df_combined.loc[condition, cryo] = df_combined.loc[condition, cryo].fillna(True)\n",
    "df_combined['CryoSleep'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mode of HomePlanet, Destination and impute it for null\n",
    "\n",
    "mode_homeplanet = df_combined['HomePlanet'].mode()[0]\n",
    "mode_destination = df_combined['Destination'].mode()[0]\n",
    "\n",
    "df_combined['HomePlanet'].fillna(mode_homeplanet, inplace=True)\n",
    "df_combined['Destination'].fillna(mode_destination, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change boolean variable cryosleep to integer values\n",
    "df_combined['CryoSleep'] = df_combined['CryoSleep'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         0\n",
       "CryoSleep          0\n",
       "Cabin            299\n",
       "Destination        0\n",
       "Age              270\n",
       "VIP              192\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "Name             294\n",
       "Transported     4277\n",
       "is_train           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute 1st IQR to replace null values in money_col\n",
    "\n",
    "cryo_sleep_1 = df_combined[df_combined['CryoSleep'] == 1]\n",
    "first_quartiles = cryo_sleep_1[money_col].quantile(0.25)\n",
    "print(first_quartiles['FoodCourt'])\n",
    "for col in money_col:\n",
    "    df_combined[col].fillna(first_quartiles[col], inplace=True)\n",
    "\n",
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_means = df_combined.groupby(['HomePlanet', 'CryoSleep', 'Destination'])['Age'].mean()\n",
    "# print(group_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Cabin and Age, input 'Z/0/N' and 'Unknown' just to use the data without deleting the row\n",
    "\n",
    "df_combined['Cabin'] = df_combined['Cabin'].fillna('Z/0/N')\n",
    "df_combined['Name'] = df_combined['Name'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since 'Cabin' column has three components, we can slit them into three columns\n",
    "\n",
    "cabin_split = df_combined['Cabin'].str.split('/', expand=True)\n",
    "cabin_split.columns = ['Deck', 'RoomNumber', 'Side']\n",
    "ndf = pd.concat([df_combined, cabin_split], axis=1)\n",
    "df_combined = ndf\n",
    "df_combined.drop(columns=['Cabin'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NA values for Age column\n",
    "\n",
    "group_means = df_combined.groupby(['CryoSleep', 'HomePlanet', 'Destination'], group_keys=True)['Age'].mean().reset_index(name='Age_mean')\n",
    "df_combined = df_combined.merge(group_means, on=['CryoSleep', 'HomePlanet', 'Destination'], how='left')\n",
    "df_combined['Age'] = df_combined['Age'].fillna(df_combined['Age_mean'])\n",
    "df_combined.drop(columns=['Age_mean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_mean_hpna = df_combined.groupby(['CryoSleep', 'Destination'], group_keys=True)['Age'].mean().reset_index(name='Age_mean_hpna')\n",
    "# group_mean_dtna = df_combined.groupby(['CryoSleep', 'HomePlanet'], group_keys=True)['Age'].mean().reset_index(name='Age_mean_dtna')\n",
    "\n",
    "# df_combined = df_combined.merge(group_mean_hpna, on=['CryoSleep', 'Destination'], how='left')\n",
    "# df_combined = df_combined.merge(group_mean_dtna, on=['CryoSleep', 'HomePlanet'], how='left')\n",
    "\n",
    "# df_combined['Age'] = df_combined.apply(\n",
    "#     lambda row: row['Age_mean_hpna'] if pd.isnull(row['HomePlanet']) and not pd.isnull(row['Age_mean_hpna']) \n",
    "#     else row['Age_mean_dtna'] if pd.isnull(row['Destination']) and not pd.isnull(row['Age_mean_dtna']) \n",
    "#     else row['Age'],\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# df_combined.drop(columns=['Age_mean_hpna', 'Age_mean_dtna'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To handle null values in VIP column, first made a new column 'TotalSpent' adding up all the money spent\n",
    "\n",
    "df_combined['TotalSpent'] = df_combined[money_col].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      273.000000\n",
       "mean      4595.542125\n",
       "std       5464.818112\n",
       "min          0.000000\n",
       "25%       1299.000000\n",
       "50%       2743.000000\n",
       "75%       6206.000000\n",
       "max      33666.000000\n",
       "Name: TotalSpent, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the minimum value of total spent when vip = 1\n",
    "\n",
    "vip = df_combined[df_combined['VIP'] == 1]\n",
    "#vip = df_combined[df_combined['VIP'] == 0]\n",
    "min_vip = vip['TotalSpent']\n",
    "min_vip.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for null vip, let's assume if a person spent over 2743 dollars, they are vips\n",
    "\n",
    "df_combined.loc[df_combined['VIP'].isnull(), 'VIP'] = df_combined['TotalSpent'] >= 2743"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet         0\n",
       "CryoSleep          0\n",
       "Destination        0\n",
       "Age                0\n",
       "VIP                0\n",
       "RoomService        0\n",
       "FoodCourt          0\n",
       "ShoppingMall       0\n",
       "Spa                0\n",
       "VRDeck             0\n",
       "Name               0\n",
       "Transported     4277\n",
       "is_train           0\n",
       "Deck               0\n",
       "RoomNumber         0\n",
       "Side               0\n",
       "TotalSpent         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>129</td>\n",
       "      <td>207</td>\n",
       "      <td>239</td>\n",
       "      <td>271</td>\n",
       "      <td>563</td>\n",
       "      <td>1565</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>127</td>\n",
       "      <td>572</td>\n",
       "      <td>508</td>\n",
       "      <td>207</td>\n",
       "      <td>313</td>\n",
       "      <td>1229</td>\n",
       "      <td>1321</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck           A    B    C    D    E     F     G  T    Z\n",
       "Transported                                             \n",
       "False        129  207  239  271  563  1565  1238  4   99\n",
       "True         127  572  508  207  313  1229  1321  1  100"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_combined, index='Transported', columns='Deck', values='PassengerId', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data for money_col is very skewed, take log and then standardize\n",
    "# taking log\n",
    "\n",
    "for column in money_col:\n",
    "   df_combined[column + '_log'] = np.log1p(df_combined[column])\n",
    "   df_combined.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding for categorical variables that will be used, and change bool to int\n",
    "\n",
    "df_combined = pd.get_dummies(df_combined, columns=['HomePlanet', 'Deck', 'Side', 'Destination'])\n",
    "df_combined['VIP'] = df_combined['VIP'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Data columns (total 32 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   PassengerId                12970 non-null  object \n",
      " 1   CryoSleep                  12970 non-null  int32  \n",
      " 2   Age                        12970 non-null  float64\n",
      " 3   VIP                        12970 non-null  int32  \n",
      " 4   Name                       12970 non-null  object \n",
      " 5   Transported                8693 non-null   object \n",
      " 6   is_train                   12970 non-null  bool   \n",
      " 7   RoomNumber                 12970 non-null  object \n",
      " 8   TotalSpent                 12970 non-null  float64\n",
      " 9   RoomService_log            12970 non-null  float64\n",
      " 10  FoodCourt_log              12970 non-null  float64\n",
      " 11  ShoppingMall_log           12970 non-null  float64\n",
      " 12  Spa_log                    12970 non-null  float64\n",
      " 13  VRDeck_log                 12970 non-null  float64\n",
      " 14  HomePlanet_Earth           12970 non-null  bool   \n",
      " 15  HomePlanet_Europa          12970 non-null  bool   \n",
      " 16  HomePlanet_Mars            12970 non-null  bool   \n",
      " 17  Deck_A                     12970 non-null  bool   \n",
      " 18  Deck_B                     12970 non-null  bool   \n",
      " 19  Deck_C                     12970 non-null  bool   \n",
      " 20  Deck_D                     12970 non-null  bool   \n",
      " 21  Deck_E                     12970 non-null  bool   \n",
      " 22  Deck_F                     12970 non-null  bool   \n",
      " 23  Deck_G                     12970 non-null  bool   \n",
      " 24  Deck_T                     12970 non-null  bool   \n",
      " 25  Deck_Z                     12970 non-null  bool   \n",
      " 26  Side_N                     12970 non-null  bool   \n",
      " 27  Side_P                     12970 non-null  bool   \n",
      " 28  Side_S                     12970 non-null  bool   \n",
      " 29  Destination_55 Cancri e    12970 non-null  bool   \n",
      " 30  Destination_PSO J318.5-22  12970 non-null  bool   \n",
      " 31  Destination_TRAPPIST-1e    12970 non-null  bool   \n",
      "dtypes: bool(19), float64(7), int32(2), object(4)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#\n",
    "#money_col_log = ['RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log']\n",
    "#scaled_columns = scaler.fit_transform(df_combined[money_col_log])\n",
    "#for i, col in enumerate(money_col_log):\n",
    "#    df_combined[col + '_scaled'] = scaled_columns[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFECV, RFE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the combined df to train and test\n",
    "\n",
    "df_combined = df_combined.drop(['Name', 'PassengerId', 'RoomNumber'], axis=1)\n",
    "df_train, df_test = separate_df(df_combined)\n",
    "df_train['Transported'] = df_train['Transported'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Transported', axis=1)\n",
    "y = df_train['Transported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918343875790684"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pipeline\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('svm', SVC())])\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8004600345025877"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_k5 = Pipeline([('Feature_Selection', SelectKBest(f_classif, k=17)),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('svm', SVC())])\n",
    "pipe_k5.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7901092581943646"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier())])\n",
    "pipe_rf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8010350776308223"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rf_k = Pipeline([('Feature_Selection', SelectKBest(f_classif, k=16)),\n",
    "                    ('scaler', StandardScaler()),\n",
    "                    ('rf', RandomForestClassifier())])\n",
    "pipe_rf_k.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kbest = SelectKBest(k=16)\n",
    "#X_new = kbest.fit_transform(X_train, y_train)\n",
    "#kbest.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimator = SVC(kernel='linear')\n",
    "#selector = RFE(estimator, step=1, verbose=1)\n",
    "#selector = selector.fit(X, y)\n",
    "#selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7573317998849913"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=333)\n",
    "selector = RFE(dt, n_features_to_select=11)\n",
    "pipe_dt = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', selector),\n",
    "    ('dt', dt)\n",
    "])\n",
    "pipe_dt.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7763082231167338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "pipe_knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest(f_classif, k=17)),\n",
    "    ('knn', knn)\n",
    "])\n",
    "pipe_knn.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.65232644\n",
      "Iteration 2, loss = 0.51494223\n",
      "Iteration 3, loss = 0.47918749\n",
      "Iteration 4, loss = 0.46259710\n",
      "Iteration 5, loss = 0.45339085\n",
      "Iteration 6, loss = 0.44811176\n",
      "Iteration 7, loss = 0.44406142\n",
      "Iteration 8, loss = 0.44127192\n",
      "Iteration 9, loss = 0.43875642\n",
      "Iteration 10, loss = 0.43640351\n",
      "Iteration 11, loss = 0.43456816\n",
      "Iteration 12, loss = 0.43228991\n",
      "Iteration 13, loss = 0.43045662\n",
      "Iteration 14, loss = 0.42830811\n",
      "Iteration 15, loss = 0.42694360\n",
      "Iteration 16, loss = 0.42607958\n",
      "Iteration 17, loss = 0.42388891\n",
      "Iteration 18, loss = 0.42257129\n",
      "Iteration 19, loss = 0.42122970\n",
      "Iteration 20, loss = 0.42034485\n",
      "Iteration 21, loss = 0.41844854\n",
      "Iteration 22, loss = 0.41700490\n",
      "Iteration 23, loss = 0.41613665\n",
      "Iteration 24, loss = 0.41473134\n",
      "Iteration 25, loss = 0.41392700\n",
      "Iteration 26, loss = 0.41290600\n",
      "Iteration 27, loss = 0.41088277\n",
      "Iteration 28, loss = 0.41024828\n",
      "Iteration 29, loss = 0.40904936\n",
      "Iteration 30, loss = 0.40827206\n",
      "Iteration 31, loss = 0.40702922\n",
      "Iteration 32, loss = 0.40608110\n",
      "Iteration 33, loss = 0.40573607\n",
      "Iteration 34, loss = 0.40434873\n",
      "Iteration 35, loss = 0.40378654\n",
      "Iteration 36, loss = 0.40323258\n",
      "Iteration 37, loss = 0.40251268\n",
      "Iteration 38, loss = 0.40125916\n",
      "Iteration 39, loss = 0.40018362\n",
      "Iteration 40, loss = 0.39962568\n",
      "Iteration 41, loss = 0.39933892\n",
      "Iteration 42, loss = 0.39838932\n",
      "Iteration 43, loss = 0.39765940\n",
      "Iteration 44, loss = 0.39712197\n",
      "Iteration 45, loss = 0.39619533\n",
      "Iteration 46, loss = 0.39526013\n",
      "Iteration 47, loss = 0.39521500\n",
      "Iteration 48, loss = 0.39453477\n",
      "Iteration 49, loss = 0.39430703\n",
      "Iteration 50, loss = 0.39453167\n",
      "Iteration 51, loss = 0.39217912\n",
      "Iteration 52, loss = 0.39165760\n",
      "Iteration 53, loss = 0.39130829\n",
      "Iteration 54, loss = 0.39030677\n",
      "Iteration 55, loss = 0.38925299\n",
      "Iteration 56, loss = 0.38963837\n",
      "Iteration 57, loss = 0.38896098\n",
      "Iteration 58, loss = 0.38849668\n",
      "Iteration 59, loss = 0.38843121\n",
      "Iteration 60, loss = 0.38736093\n",
      "Iteration 61, loss = 0.38670293\n",
      "Iteration 62, loss = 0.38614689\n",
      "Iteration 63, loss = 0.38560086\n",
      "Iteration 64, loss = 0.38473794\n",
      "Iteration 65, loss = 0.38493605\n",
      "Iteration 66, loss = 0.38447844\n",
      "Iteration 67, loss = 0.38324666\n",
      "Iteration 68, loss = 0.38281901\n",
      "Iteration 69, loss = 0.38297531\n",
      "Iteration 70, loss = 0.38202089\n",
      "Iteration 71, loss = 0.38130173\n",
      "Iteration 72, loss = 0.38170681\n",
      "Iteration 73, loss = 0.38216042\n",
      "Iteration 74, loss = 0.38092345\n",
      "Iteration 75, loss = 0.37982311\n",
      "Iteration 76, loss = 0.38049029\n",
      "Iteration 77, loss = 0.37919734\n",
      "Iteration 78, loss = 0.37873451\n",
      "Iteration 79, loss = 0.37843952\n",
      "Iteration 80, loss = 0.37862530\n",
      "Iteration 81, loss = 0.37885483\n",
      "Iteration 82, loss = 0.37732856\n",
      "Iteration 83, loss = 0.37863754\n",
      "Iteration 84, loss = 0.37546722\n",
      "Iteration 85, loss = 0.37636710\n",
      "Iteration 86, loss = 0.37612881\n",
      "Iteration 87, loss = 0.37603514\n",
      "Iteration 88, loss = 0.37535638\n",
      "Iteration 89, loss = 0.37517420\n",
      "Iteration 90, loss = 0.37407216\n",
      "Iteration 91, loss = 0.37414911\n",
      "Iteration 92, loss = 0.37392201\n",
      "Iteration 93, loss = 0.37292473\n",
      "Iteration 94, loss = 0.37306509\n",
      "Iteration 95, loss = 0.37184897\n",
      "Iteration 96, loss = 0.37270713\n",
      "Iteration 97, loss = 0.37234229\n",
      "Iteration 98, loss = 0.37178218\n",
      "Iteration 99, loss = 0.37216293\n",
      "Iteration 100, loss = 0.37091084\n",
      "Iteration 101, loss = 0.37084573\n",
      "Iteration 102, loss = 0.37221701\n",
      "Iteration 103, loss = 0.37096290\n",
      "Iteration 104, loss = 0.36968762\n",
      "Iteration 105, loss = 0.37000719\n",
      "Iteration 106, loss = 0.37060957\n",
      "Iteration 107, loss = 0.36815321\n",
      "Iteration 108, loss = 0.36824265\n",
      "Iteration 109, loss = 0.36769573\n",
      "Iteration 110, loss = 0.36759300\n",
      "Iteration 111, loss = 0.36782992\n",
      "Iteration 112, loss = 0.36807423\n",
      "Iteration 113, loss = 0.36698133\n",
      "Iteration 114, loss = 0.36585077\n",
      "Iteration 115, loss = 0.36683951\n",
      "Iteration 116, loss = 0.36571373\n",
      "Iteration 117, loss = 0.36487815\n",
      "Iteration 118, loss = 0.36522257\n",
      "Iteration 119, loss = 0.36609569\n",
      "Iteration 120, loss = 0.36638352\n",
      "Iteration 121, loss = 0.36596074\n",
      "Iteration 122, loss = 0.36414553\n",
      "Iteration 123, loss = 0.36412284\n",
      "Iteration 124, loss = 0.36550372\n",
      "Iteration 125, loss = 0.36452826\n",
      "Iteration 126, loss = 0.36416874\n",
      "Iteration 127, loss = 0.36400915\n",
      "Iteration 128, loss = 0.36264970\n",
      "Iteration 129, loss = 0.36239890\n",
      "Iteration 130, loss = 0.36312534\n",
      "Iteration 131, loss = 0.36205104\n",
      "Iteration 132, loss = 0.36278656\n",
      "Iteration 133, loss = 0.36080223\n",
      "Iteration 134, loss = 0.36128442\n",
      "Iteration 135, loss = 0.36195588\n",
      "Iteration 136, loss = 0.36098564\n",
      "Iteration 137, loss = 0.36085663\n",
      "Iteration 138, loss = 0.36044645\n",
      "Iteration 139, loss = 0.36160034\n",
      "Iteration 140, loss = 0.35968499\n",
      "Iteration 141, loss = 0.35996057\n",
      "Iteration 142, loss = 0.35944754\n",
      "Iteration 143, loss = 0.36050376\n",
      "Iteration 144, loss = 0.35855504\n",
      "Iteration 145, loss = 0.35936073\n",
      "Iteration 146, loss = 0.35848948\n",
      "Iteration 147, loss = 0.35822647\n",
      "Iteration 148, loss = 0.35765490\n",
      "Iteration 149, loss = 0.35763191\n",
      "Iteration 150, loss = 0.35749821\n",
      "Iteration 151, loss = 0.35693701\n",
      "Iteration 152, loss = 0.35710482\n",
      "Iteration 153, loss = 0.35770522\n",
      "Iteration 154, loss = 0.35809137\n",
      "Iteration 155, loss = 0.35649419\n",
      "Iteration 156, loss = 0.35708966\n",
      "Iteration 157, loss = 0.35598276\n",
      "Iteration 158, loss = 0.35628672\n",
      "Iteration 159, loss = 0.35613640\n",
      "Iteration 160, loss = 0.35493339\n",
      "Iteration 161, loss = 0.35400528\n",
      "Iteration 162, loss = 0.35498382\n",
      "Iteration 163, loss = 0.35459017\n",
      "Iteration 164, loss = 0.35509455\n",
      "Iteration 165, loss = 0.35532028\n",
      "Iteration 166, loss = 0.35373391\n",
      "Iteration 167, loss = 0.35352127\n",
      "Iteration 168, loss = 0.35371789\n",
      "Iteration 169, loss = 0.35475471\n",
      "Iteration 170, loss = 0.35358738\n",
      "Iteration 171, loss = 0.35215936\n",
      "Iteration 172, loss = 0.35323057\n",
      "Iteration 173, loss = 0.35208008\n",
      "Iteration 174, loss = 0.35187397\n",
      "Iteration 175, loss = 0.35100974\n",
      "Iteration 176, loss = 0.35108986\n",
      "Iteration 177, loss = 0.35087396\n",
      "Iteration 178, loss = 0.35150991\n",
      "Iteration 179, loss = 0.35104048\n",
      "Iteration 180, loss = 0.35190549\n",
      "Iteration 181, loss = 0.35137408\n",
      "Iteration 182, loss = 0.35144615\n",
      "Iteration 183, loss = 0.35112229\n",
      "Iteration 184, loss = 0.35068122\n",
      "Iteration 185, loss = 0.34902576\n",
      "Iteration 186, loss = 0.34940340\n",
      "Iteration 187, loss = 0.34836118\n",
      "Iteration 188, loss = 0.35038360\n",
      "Iteration 189, loss = 0.35060151\n",
      "Iteration 190, loss = 0.35007029\n",
      "Iteration 191, loss = 0.34812111\n",
      "Iteration 192, loss = 0.34822465\n",
      "Iteration 193, loss = 0.34845248\n",
      "Iteration 194, loss = 0.34870488\n",
      "Iteration 195, loss = 0.34847778\n",
      "Iteration 196, loss = 0.34785302\n",
      "Iteration 197, loss = 0.34872330\n",
      "Iteration 198, loss = 0.34808617\n",
      "Iteration 199, loss = 0.34662005\n",
      "Iteration 200, loss = 0.34820641\n",
      "Iteration 201, loss = 0.34678740\n",
      "Iteration 202, loss = 0.34738819\n",
      "Iteration 203, loss = 0.34551260\n",
      "Iteration 204, loss = 0.34713044\n",
      "Iteration 205, loss = 0.34643356\n",
      "Iteration 206, loss = 0.34650364\n",
      "Iteration 207, loss = 0.34697704\n",
      "Iteration 208, loss = 0.34605136\n",
      "Iteration 209, loss = 0.34501167\n",
      "Iteration 210, loss = 0.34611037\n",
      "Iteration 211, loss = 0.34467957\n",
      "Iteration 212, loss = 0.34539898\n",
      "Iteration 213, loss = 0.34591747\n",
      "Iteration 214, loss = 0.34434429\n",
      "Iteration 215, loss = 0.34442180\n",
      "Iteration 216, loss = 0.34527862\n",
      "Iteration 217, loss = 0.34415361\n",
      "Iteration 218, loss = 0.34390930\n",
      "Iteration 219, loss = 0.34496160\n",
      "Iteration 220, loss = 0.34396827\n",
      "Iteration 221, loss = 0.34362842\n",
      "Iteration 222, loss = 0.34337316\n",
      "Iteration 223, loss = 0.34243186\n",
      "Iteration 224, loss = 0.34238365\n",
      "Iteration 225, loss = 0.34266952\n",
      "Iteration 226, loss = 0.34178174\n",
      "Iteration 227, loss = 0.34258836\n",
      "Iteration 228, loss = 0.34319368\n",
      "Iteration 229, loss = 0.34125084\n",
      "Iteration 230, loss = 0.34166909\n",
      "Iteration 231, loss = 0.34180072\n",
      "Iteration 232, loss = 0.34186245\n",
      "Iteration 233, loss = 0.34131227\n",
      "Iteration 234, loss = 0.34350861\n",
      "Iteration 235, loss = 0.34241278\n",
      "Iteration 236, loss = 0.33968914\n",
      "Iteration 237, loss = 0.34068855\n",
      "Iteration 238, loss = 0.34017770\n",
      "Iteration 239, loss = 0.33959904\n",
      "Iteration 240, loss = 0.33846460\n",
      "Iteration 241, loss = 0.33911145\n",
      "Iteration 242, loss = 0.33979684\n",
      "Iteration 243, loss = 0.33914955\n",
      "Iteration 244, loss = 0.34041556\n",
      "Iteration 245, loss = 0.33987544\n",
      "Iteration 246, loss = 0.33926029\n",
      "Iteration 247, loss = 0.33876222\n",
      "Iteration 248, loss = 0.33932494\n",
      "Iteration 249, loss = 0.33821342\n",
      "Iteration 250, loss = 0.33923116\n",
      "Iteration 251, loss = 0.33850119\n",
      "Iteration 252, loss = 0.33808706\n",
      "Iteration 253, loss = 0.33793688\n",
      "Iteration 254, loss = 0.33669496\n",
      "Iteration 255, loss = 0.33755367\n",
      "Iteration 256, loss = 0.33853224\n",
      "Iteration 257, loss = 0.33693569\n",
      "Iteration 258, loss = 0.33770758\n",
      "Iteration 259, loss = 0.33746377\n",
      "Iteration 260, loss = 0.33815782\n",
      "Iteration 261, loss = 0.33706000\n",
      "Iteration 262, loss = 0.33649743\n",
      "Iteration 263, loss = 0.33610910\n",
      "Iteration 264, loss = 0.33834120\n",
      "Iteration 265, loss = 0.33543172\n",
      "Iteration 266, loss = 0.33496276\n",
      "Iteration 267, loss = 0.33507877\n",
      "Iteration 268, loss = 0.33397857\n",
      "Iteration 269, loss = 0.33424997\n",
      "Iteration 270, loss = 0.33533408\n",
      "Iteration 271, loss = 0.33592629\n",
      "Iteration 272, loss = 0.33543878\n",
      "Iteration 273, loss = 0.33456260\n",
      "Iteration 274, loss = 0.33393499\n",
      "Iteration 275, loss = 0.33458805\n",
      "Iteration 276, loss = 0.33547249\n",
      "Iteration 277, loss = 0.33470314\n",
      "Iteration 278, loss = 0.33407591\n",
      "Iteration 279, loss = 0.33341961\n",
      "Iteration 280, loss = 0.33379343\n",
      "Iteration 281, loss = 0.33343052\n",
      "Iteration 282, loss = 0.33278769\n",
      "Iteration 283, loss = 0.33392966\n",
      "Iteration 284, loss = 0.33341352\n",
      "Iteration 285, loss = 0.33252309\n",
      "Iteration 286, loss = 0.33255198\n",
      "Iteration 287, loss = 0.33185425\n",
      "Iteration 288, loss = 0.33220283\n",
      "Iteration 289, loss = 0.33122444\n",
      "Iteration 290, loss = 0.33159077\n",
      "Iteration 291, loss = 0.33330419\n",
      "Iteration 292, loss = 0.33232061\n",
      "Iteration 293, loss = 0.33231741\n",
      "Iteration 294, loss = 0.33103789\n",
      "Iteration 295, loss = 0.33050261\n",
      "Iteration 296, loss = 0.33230184\n",
      "Iteration 297, loss = 0.33160584\n",
      "Iteration 298, loss = 0.33044385\n",
      "Iteration 299, loss = 0.33018597\n",
      "Iteration 300, loss = 0.33004604\n",
      "Iteration 301, loss = 0.33034553\n",
      "Iteration 302, loss = 0.33114925\n",
      "Iteration 303, loss = 0.32972139\n",
      "Iteration 304, loss = 0.33022661\n",
      "Iteration 305, loss = 0.32965758\n",
      "Iteration 306, loss = 0.33008433\n",
      "Iteration 307, loss = 0.33043498\n",
      "Iteration 308, loss = 0.32842658\n",
      "Iteration 309, loss = 0.32829497\n",
      "Iteration 310, loss = 0.32851728\n",
      "Iteration 311, loss = 0.32964163\n",
      "Iteration 312, loss = 0.32840269\n",
      "Iteration 313, loss = 0.32908861\n",
      "Iteration 314, loss = 0.32805143\n",
      "Iteration 315, loss = 0.32747202\n",
      "Iteration 316, loss = 0.32807357\n",
      "Iteration 317, loss = 0.32789445\n",
      "Iteration 318, loss = 0.32741761\n",
      "Iteration 319, loss = 0.32810560\n",
      "Iteration 320, loss = 0.32825515\n",
      "Iteration 321, loss = 0.32709661\n",
      "Iteration 322, loss = 0.32683167\n",
      "Iteration 323, loss = 0.32795228\n",
      "Iteration 324, loss = 0.32707442\n",
      "Iteration 325, loss = 0.32648775\n",
      "Iteration 326, loss = 0.32794863\n",
      "Iteration 327, loss = 0.32617365\n",
      "Iteration 328, loss = 0.32707512\n",
      "Iteration 329, loss = 0.32534549\n",
      "Iteration 330, loss = 0.32464707\n",
      "Iteration 331, loss = 0.32569788\n",
      "Iteration 332, loss = 0.32853962\n",
      "Iteration 333, loss = 0.32662874\n",
      "Iteration 334, loss = 0.32441535\n",
      "Iteration 335, loss = 0.32599812\n",
      "Iteration 336, loss = 0.32465746\n",
      "Iteration 337, loss = 0.32566847\n",
      "Iteration 338, loss = 0.32446424\n",
      "Iteration 339, loss = 0.32595934\n",
      "Iteration 340, loss = 0.32483877\n",
      "Iteration 341, loss = 0.32442658\n",
      "Iteration 342, loss = 0.32429076\n",
      "Iteration 343, loss = 0.32380103\n",
      "Iteration 344, loss = 0.32432914\n",
      "Iteration 345, loss = 0.32495147\n",
      "Iteration 346, loss = 0.32360371\n",
      "Iteration 347, loss = 0.32308555\n",
      "Iteration 348, loss = 0.32321673\n",
      "Iteration 349, loss = 0.32240558\n",
      "Iteration 350, loss = 0.32555982\n",
      "Iteration 351, loss = 0.32360561\n",
      "Iteration 352, loss = 0.32607477\n",
      "Iteration 353, loss = 0.32435980\n",
      "Iteration 354, loss = 0.32550100\n",
      "Iteration 355, loss = 0.32407667\n",
      "Iteration 356, loss = 0.32468992\n",
      "Iteration 357, loss = 0.32347761\n",
      "Iteration 358, loss = 0.32566914\n",
      "Iteration 359, loss = 0.32427189\n",
      "Iteration 360, loss = 0.32273484\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7964347326049454"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, alpha=1e-4,\n",
    "                    solver='adam', verbose=True, random_state=333,\n",
    "                    learning_rate_init=.001)\n",
    "pipe_mlp = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mlp', mlp)\n",
    "])\n",
    "pipe_mlp.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
