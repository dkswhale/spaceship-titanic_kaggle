{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.46.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\s_torileeo99\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install numpy\n",
    "%pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will combine train and test set, creating a column 'is_train'\n",
    "# for later when we separate them back\n",
    "def concat_df(train, test):\n",
    "    test['is_train'] = False\n",
    "    train['is_train'] = True\n",
    "    combined = pd.concat([train, test], sort=False)\n",
    "    return combined\n",
    "\n",
    "# function that will separate the combined df\n",
    "def separate_df(combined):\n",
    "    train = combined[combined['is_train'] == True].drop('is_train', axis=1)\n",
    "    test = combined[combined['is_train'] == False].drop('is_train', axis=1)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine test and train data to preprocess the data all together.\n",
    "df_combined = concat_df(df_train, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12970 entries, 0 to 4276\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   12970 non-null  object \n",
      " 1   HomePlanet    12682 non-null  object \n",
      " 2   CryoSleep     12660 non-null  object \n",
      " 3   Cabin         12671 non-null  object \n",
      " 4   Destination   12696 non-null  object \n",
      " 5   Age           12700 non-null  float64\n",
      " 6   VIP           12674 non-null  object \n",
      " 7   RoomService   12707 non-null  float64\n",
      " 8   FoodCourt     12681 non-null  float64\n",
      " 9   ShoppingMall  12664 non-null  float64\n",
      " 10  Spa           12686 non-null  float64\n",
      " 11  VRDeck        12702 non-null  float64\n",
      " 12  Name          12676 non-null  object \n",
      " 13  Transported   8693 non-null   object \n",
      " 14  is_train      12970 non-null  bool   \n",
      "dtypes: bool(1), float64(6), object(8)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person is in cryosleep, they would not be able to spend any money so\n",
    "# we can fill null with 0 for money spent columns and false for VIP column\n",
    "money_col = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
    "vip = ['VIP']\n",
    "condition = (df_combined['CryoSleep'] == True)\n",
    "\n",
    "df_combined.loc[condition, money_col] = df_combined.loc[condition, money_col].fillna(0)\n",
    "df_combined.loc[condition, vip] = df_combined.loc[condition, vip].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a person have not spent any money, it is likely that person is in cryosleep.\n",
    "cryo = ['CryoSleep']\n",
    "\n",
    "# the condition is True if all the money_col values are 0\n",
    "condition = (df_combined[money_col].eq(0).all(axis=1))\n",
    "\n",
    "df_combined.loc[condition, cryo] = df_combined.loc[condition, cryo].fillna(True)\n",
    "df_combined['CryoSleep'].fillna(False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data for money_col is very skewed, take log and then standardize\n",
    "# taking log\n",
    "\n",
    "for column in money_col:\n",
    "    df_combined[column + '_log'] = np.log1p(df_combined[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet       288\n",
       "CryoSleep          0\n",
       "Cabin            299\n",
       "Destination      274\n",
       "Age              270\n",
       "VIP              192\n",
       "RoomService      170\n",
       "FoodCourt        180\n",
       "ShoppingMall     175\n",
       "Spa              177\n",
       "VRDeck           177\n",
       "Name             294\n",
       "Transported     4277\n",
       "is_train           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since 'Cabin' column has three components, we can slit them into three columns\n",
    "\n",
    "cabin_split = df_combined['Cabin'].str.split('/', expand=True)\n",
    "cabin_split.columns = ['Deck', 'RoomNumber', 'Side']\n",
    "ndf = pd.concat([df_combined, cabin_split], axis=1)\n",
    "df_combined = ndf\n",
    "df_combined.drop(columns=['Cabin'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HomePlanet  CryoSleep  Destination  \n",
      "Earth       False      55 Cancri e      24.101341\n",
      "                       PSO J318.5-22    29.400391\n",
      "                       TRAPPIST-1e      27.525610\n",
      "            True       55 Cancri e      21.093960\n",
      "                       PSO J318.5-22    24.065913\n",
      "                       TRAPPIST-1e      23.274959\n",
      "Europa      False      55 Cancri e      36.318328\n",
      "                       PSO J318.5-22    36.307692\n",
      "                       TRAPPIST-1e      35.037146\n",
      "            True       55 Cancri e      32.905775\n",
      "                       PSO J318.5-22    33.562500\n",
      "                       TRAPPIST-1e      32.797950\n",
      "Mars        False      55 Cancri e      26.369048\n",
      "                       PSO J318.5-22    35.140000\n",
      "                       TRAPPIST-1e      30.036870\n",
      "            True       55 Cancri e      27.561983\n",
      "                       PSO J318.5-22    40.533333\n",
      "                       TRAPPIST-1e      28.753172\n",
      "Name: Age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "group_means = df_combined.groupby(['HomePlanet', 'CryoSleep', 'Destination'])['Age'].mean()\n",
    "print(group_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in NA values for Age column\n",
    "\n",
    "group_means = df_combined.groupby(['CryoSleep', 'HomePlanet', 'Destination'], group_keys=True)['Age'].mean().reset_index(name='Age_mean')\n",
    "df_combined = df_combined.merge(group_means, on=['CryoSleep', 'HomePlanet', 'Destination'], how='left')\n",
    "df_combined['Age'] = df_combined['Age'].fillna(df_combined['Age_mean'])\n",
    "df_combined.drop(columns=['Age_mean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transported</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>129</td>\n",
       "      <td>207</td>\n",
       "      <td>239</td>\n",
       "      <td>271</td>\n",
       "      <td>563</td>\n",
       "      <td>1565</td>\n",
       "      <td>1238</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>127</td>\n",
       "      <td>572</td>\n",
       "      <td>508</td>\n",
       "      <td>207</td>\n",
       "      <td>313</td>\n",
       "      <td>1229</td>\n",
       "      <td>1321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck           A    B    C    D    E     F     G  T\n",
       "Transported                                        \n",
       "False        129  207  239  271  563  1565  1238  4\n",
       "True         127  572  508  207  313  1229  1321  1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(df_combined, index='Transported', columns='Deck', values='PassengerId', aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId        0\n",
       "HomePlanet       288\n",
       "CryoSleep          0\n",
       "Destination      274\n",
       "Age               13\n",
       "VIP              192\n",
       "RoomService      170\n",
       "FoodCourt        180\n",
       "ShoppingMall     175\n",
       "Spa              177\n",
       "VRDeck           177\n",
       "Name             294\n",
       "Transported     4277\n",
       "is_train           0\n",
       "Deck             299\n",
       "RoomNumber       299\n",
       "Side             299\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the data for money_col is very skewed, take log and then standardize\n",
    "# taking log\n",
    "\n",
    "for column in money_col:\n",
    "    df_combined[column + '_log'] = np.log1p(df_combined[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "#scaler = StandardScaler()\n",
    "\n",
    "money_col_log = ['RoomService_log', 'FoodCourt_log', 'ShoppingMall_log', 'Spa_log', 'VRDeck_log']\n",
    "#scaled_columns = scaler.fit_transform(df_combined[money_col_log])\n",
    "#for i, col in enumerate(money_col_log):\n",
    "#    df_combined[col + '_scaled'] = scaled_columns[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12970 entries, 0 to 12969\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   PassengerId       12970 non-null  object \n",
      " 1   HomePlanet        12682 non-null  object \n",
      " 2   CryoSleep         12970 non-null  bool   \n",
      " 3   Destination       12696 non-null  object \n",
      " 4   Age               12957 non-null  float64\n",
      " 5   VIP               12778 non-null  object \n",
      " 6   RoomService       12800 non-null  float64\n",
      " 7   FoodCourt         12790 non-null  float64\n",
      " 8   ShoppingMall      12795 non-null  float64\n",
      " 9   Spa               12793 non-null  float64\n",
      " 10  VRDeck            12793 non-null  float64\n",
      " 11  Name              12676 non-null  object \n",
      " 12  Transported       8693 non-null   object \n",
      " 13  is_train          12970 non-null  bool   \n",
      " 14  Deck              12671 non-null  object \n",
      " 15  RoomNumber        12671 non-null  object \n",
      " 16  Side              12671 non-null  object \n",
      " 17  RoomService_log   12800 non-null  float64\n",
      " 18  FoodCourt_log     12790 non-null  float64\n",
      " 19  ShoppingMall_log  12795 non-null  float64\n",
      " 20  Spa_log           12793 non-null  float64\n",
      " 21  VRDeck_log        12793 non-null  float64\n",
      "dtypes: bool(2), float64(11), object(9)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_combined.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change boolean variable cryosleep to integer values\n",
    "df_combined['CryoSleep'] = df_combined['CryoSleep'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform one-hot encoding for categorical variables that will be used\n",
    "\n",
    "df_combined = pd.get_dummies(df_combined, columns=['HomePlanet', 'Deck', 'Side', 'Destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                     0\n",
       "CryoSleep                       0\n",
       "Age                             0\n",
       "VIP                           192\n",
       "RoomService                   170\n",
       "FoodCourt                     180\n",
       "ShoppingMall                  175\n",
       "Spa                           177\n",
       "VRDeck                        177\n",
       "Name                          294\n",
       "Transported                  4269\n",
       "is_train                        0\n",
       "RoomNumber                    299\n",
       "RoomService_log               170\n",
       "FoodCourt_log                 180\n",
       "ShoppingMall_log              175\n",
       "Spa_log                       177\n",
       "VRDeck_log                    177\n",
       "HomePlanet_Earth                0\n",
       "HomePlanet_Europa               0\n",
       "HomePlanet_Mars                 0\n",
       "Deck_A                          0\n",
       "Deck_B                          0\n",
       "Deck_C                          0\n",
       "Deck_D                          0\n",
       "Deck_E                          0\n",
       "Deck_F                          0\n",
       "Deck_G                          0\n",
       "Deck_T                          0\n",
       "Side_P                          0\n",
       "Side_S                          0\n",
       "Destination_55 Cancri e         0\n",
       "Destination_PSO J318.5-22       0\n",
       "Destination_TRAPPIST-1e         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined = df_combined.dropna(subset=['Age'])\n",
    "#df_combined.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RoomService'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\s_torileeo99\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RoomService'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m roomservice \u001b[38;5;241m=\u001b[39m df_combined\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf_combined\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRoomService\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m roomservice \u001b[38;5;241m=\u001b[39m roomservice[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoomService\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m df_combined\u001b[38;5;241m=\u001b[39m df_combined[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRoomService\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(roomservice\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;241m.25\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\s_torileeo99\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\s_torileeo99\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\s_torileeo99\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RoomService'"
     ]
    }
   ],
   "source": [
    "roomservice = df_combined.loc[df_combined['RoomService'] != 0]\n",
    "roomservice = roomservice['RoomService']\n",
    "df_combined= df_combined['RoomService'].fillna(roomservice.quantile(.25))\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the combined df to train and test\n",
    "df_combined = df_combined.drop(['Name', 'PassengerId', 'RoomNumber'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_combined['Transported'].astype(int)\n",
    "df_train, df_test = separate_df(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('Transported', axis=1)\n",
    "y = df_train['Transported']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "preprocessor = ColumnTransformer(transformers = [('scaler', StandardScaler(), money_col_log)],\n",
    "                                                 remainder='passthrough')\n",
    "\n",
    "pipe = Pipeline([('preprocessor', preprocessor), ('svc', SVC())])\n",
    "\n",
    "pipe.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
